---
title: "MTech Projects"
layout: default
excerpt: "VCLab, CDS, IISc"
sitemap: false
permalink: /mtech_projects/
---


#### âœ¨ Project Title-1: "FrameEdit: In-Context Temporal Frame Generation via LLMâ€“Diffusion Fusion"
Details: Extending the capabilities of [GenHowTo](https://arxiv.org/abs/2312.07322) and [ShowHowTo](https://arxiv.org/abs/2412.01987), we aim to generate the nâ€™th frame from given initial frames while ensuring temporal and structural consistency aligned with given new action prompts. We frame this as an in-context editing problem, leveraging fused Autoregressive LLMs and Generative Diffusion Transformers inspired by [Jenus-Pro](https://arxiv.org/abs/2501.17811), [OmniGen](https://arxiv.org/abs/2409.11340), and [OmniGen-v2](https://arxiv.org/abs/2506.18871), with significant potential for applications such as robotics, AR, VR etc.

<br>
<br>
ðŸ”— Contact person for more details: Shyam Marjit <a href="mailto:shyam.marjit@iisc.ac.in">Shyam Marjit</a>



#### âœ¨ Project Title-2: "AudioLLM: On-the-fly interactive audio unmixing and editing"
Details: Inspired by [SegLLM](https://berkeley-hipie.github.io/segllm.github.io/), this project aims to design an interactive video-to-audio editing chatbot system that processes videos (real-world and synthetic) containing audio. The goal is to decompose the input audio into multiple object-centric audio tracks (refer to this [paper](https://arxiv.org/abs/2506.20995)) and associate each track with its corresponding visual object in the video. The chatbot further enables fine-grained editing of these object-centric audio components, allowing users to modify them individually or collectively according to their preferences.


ðŸ”— Contact person for more details: Shyam Marjit <a href="mailto:shyam.marjit@iisc.ac.in">Shyam Marjit</a>
